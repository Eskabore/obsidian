---
tags: upload, aws
---
# Image Upload - Part 2

As alluded to [[Image Upload|earlier]], storing uploaded files on your server's file system is not adequate in most production environments. Why is that? Well, imagine you are deploying your site to [[Render]]. The file system on Heroku dynos is ephemeral - it goes away every time you deploy. So with every update to your site, all the previously uploaded files will disappear. Many other deployment environments will have a similar situation. Apart from that, imagine that for scaling purposes your code is running on multiple different servers. If the files are stored on the server that receives them, none of the other servers would have them and be able to handle requests for them.

What is needed is a centralized location where files can be reliably stored. There are many services that offer precisely this along with many other benefits. One of the most widely used is Amazon's Simple Storage Service, which is usually referred to as [S3](https://aws.amazon.com/s3).

## AWS

You can create your own [Amazon Web Services account](https://aws.amazon.com/free/) and use 5GB of S3 storage for free for one year (as well as many other AWS offerings with similar limitations). However, to create your account you have to enter a credit card to cover expenses if you go over the free tier limits. If you would rather not do that, you can [[AWS|get credentials]] for an account that has already been set up for you to use.

If you create your own account, you can open the Services menu to see the dizzying array of web services that AWS offers. There are two you will be immediately interested in: IAM (Identity Access Management) and S3.

![[Pasted image 20230120222827.png]]



### IAM

You should start with IAM. There you can create a user and assign it to a group. You want to create a user so that you can use its credentials in your app to access S3 and you want to add the user to a group because it is by being members of groups that users gain permission to access AWS services. You want this because you do not want to use your own credentials. The credentials belonging to the owner of the AWS account have full powers to do anything with it. It would be disastrous if your credentials are compromised. To mitigate this risk, you should create a group that has limited permissions and use a member of that group's credentials in your app.

![[Pasted image 20230120222944.png]]


You should click the Add User button to begin the process of creating a user and a group. You should give your new user programmatic access. That will allow you to use the user's credentials in your app.

![[Pasted image 20230120223008.png]]

When it comes time to add the user to a group you will have to create one. You should assign to it the AmazonS3FullAccess policy. That is the only permission it needs.

![[Pasted image 20230120223032.png]]

You do not need to give your user any tags. Tags are for finding similar users when you have lots of them and you will only have one.

When the process is complete, you will have the opportunity to download or copy your access key and secret. This will be the only time you have this opportunity. If you lose track of your key and secret, you will have to generate a new set for your user.

![[Pasted image 20230120223107.png]]

It is of critical importance that you **DO NOT COMMIT YOUR CREDENTIALS**. If you do accidentally commit them, you should consider them compromised and return to the IAM console to invalidate them and generate new ones immediately. It is too easy for credentials that have been committed to become public.

To avoid committing your access key and secret, you should put them in a json file whose name is listed in your .gitignore file in your repository. You can then require the json file in your app when it is running in your development environment. In your production environment, you would have to work out another way to make the credentials available. If you are using Heroku, you can set them as config vars to make them available as properties of `process.env`.

### S3

Once you have your credentials squared away, you should create an S3 bucket. You can think of a bucket as a space or a folder you can store files in. In S3 lingo, the files you store in a bucket are called objects.

Bucket names must be unique across all accounts so you may not be able to get the exact one you want. The name of your bucket may appear in urls as either part of the path or hostname. It would be a mistake to give your bucket a name containing characters that would not work in those positions such as spaces, dots, etc. You should stick to letters, numbers, minus and underscore.

When selecting a region you should choose US East (N. Virginia). This will make your bucket fully available immediately. If you choose a different region, you will have to wait an indeterminate amount of time before you can successfully upload files to it in your app.

![[Pasted image 20230120223131.png]]


The only other options you need to set during the bucket creation process are related to object permissions. You want to adjust your bucket's permissions:

![[Pasted image 20230120223146.png]]

And you want to enable ACLs (Access Control List):

![[Pasted image 20230120223227.png]]

By default, all objects added to a bucket are private. You will want to make it so objects can be made publicly accessible through the addition of an ACL (access control list).

## AWS SDK

The [AWS SDK for Node.js](https://aws.amazon.com/sdk-for-node-js/) allows you to work with Amazon Web Services in your Node app. It is already installed in your Image Board project.

The first thing you need to do in your code is require the module and use it to create an S3 client.

```js
const aws = require('aws-sdk');

let secrets;
if (process.env.NODE_ENV == 'production') {
    secrets = process.env; // in prod the secrets are environment variables
} else {
    secrets = require('./secrets'); // in dev they are in secrets.json which is listed in .gitignore
}

const s3 = new aws.S3({
    accessKeyId: secrets.AWS_KEY,
    secretAccessKey: secrets.AWS_SECRET
});
```

You can then call the [`putObject`](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#putObject-property) method of the `S3` instance you created to upload a file. By default, this method expects a callback but it returns an object with a method named `promise` that you can call to get a promise.

When you call `putObject`, you will have to pass it an object containing the following properties (which are annoyingly capitalized for some reason):

1.  `Bucket` - this should be set to the name of your bucket
    
2.  `ACL` - this should be set to `'public-read'` so anybody can view the file after it is uploaded
    
3.  `Key` - in S3 lingo, keys are then names of files in a bucket. For this you can use the `filename` property of the `req.file` object created by `multer`. It will be the unique name you generated using `uid-safe`
    
4.  `Body` - this should be set to a stream you create by calling `fs.createReadStream` and passing to it the path to the uploaded file. The path is available as a property of `req.file`
    
5.  `ContentType` - this will be the value of the `Content-Type` header S3 uses when it serves your file. You can use the `mimetype` property of `req.file` for this
    
6.  `ContentLength` - You can use the `size` property of `req.file` for this
    

```js
const fs = require('fs');

const {filename, mimetype, size, path} = req.file;

const promise = s3.putObject({
    Bucket: 'spicedling',
    ACL: 'public-read',
    Key: filename,
    Body: fs.createReadStream(path),
    ContentType: mimetype,
    ContentLength: size
}).promise();

promise.then(
    () => {
        // it worked!!!
    }
).catch(
    err => {
        // uh oh
        console.log(err);
    }
);
```

If the PUT is successful, your file will be available for the world to see at `https://s3.amazonaws.com/:yourBucketName/:filename`. If you chose another "region" when you created your S3 bucket, the URL for your file will be different. Potentially: `https://:yourBucketName.s3.eu-central-1.amazonaws.com/:filename`.

### When to do this

Obviously, it is required for multer to have done it's thing for you to be able to do this. The code above depends on there being a `req.file`, and there won't be one until the function returned by your call to `uploader.single` has run. You probably also want to upload the image to S3 before you update your database with the file name and send a response to the user. It would be better not to store the file name if you could not get the file onto S3, and if you don't store the file name, your response should inform the user of the failure.

One option would be to do the `putObject` call in a middleware function that runs after the function returned by `uploader.single`. This function could call `next` after success, giving the route the opportunity to update the database and send a response.

Another alternative would be to write a function that you can call from the route. The route would have to pass `req.file` to the function and the function would have to return a promise so you can know when the file has been successfully uploaded.

#### Added by **Jan** on November 18, 2022

## (Possible) order of steps

-   create the form
-   add multer config from the previous lesson (upload image to the upload folder)
-   add the aws configuration (start the server if the config and all the credentials are correct)
-   add the vue js part for the upload (new FormData()...)
-   implement the upload to aws in server.js
-   in the post image route on the server send a response that contains the url of the uploaded image
-   when that response is in the client, update the list of images in vue

#### index.html

```html
<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Image Board</title>
    <style>
        .headline {
            color: blue;
        }

        label, input {
            display: block;
            clear: both;
        }
    </style>
</head>

<body>
    <div id="main">
        <!-- <h1 :class.camel="headlineCssClass">{{ headline }}</h1>
        <h2 v-on:mouseover="emphasize" @mouseout="deemphasize">Hello {{ name || "you" }} </h2>
        <ul v-if="cities.length > 0">
            cities:
            <li v-for="city in cities">{{city.name}}, {{city.country}}</li>
        </ul>
        <div>{{ count }}</div>
        <div>{{ state }}</div> -->
        <form>
            <label for="title">Title</label>
            <input type="text" name="title" id="">
            <label for="description">Description</label>
            <input type="text" name="description" id="">
            <label for="username">Username</label>
            <input type="text" name="username" id="">
            <label for="file">File</label>
            <input type="file" name="file" id="">
            <input type="button" value="Upload" @click="uploadImage">
        </form>
    </div>
    <script src="/js/app.js" type="module" crossorigin="use-credentials"></script>
</body>

</html>
```

#### server.js

```js
const path = require("path");
const express = require("express");
const path = require("path");
const express = require("express");
const app = express();
const fs = require("fs");
require("dotenv").config();
const { PORT = 8080 } = process.env;

const multer = require("multer");
const uidSafe = require("uid-safe");

const diskStorage = multer.diskStorage({
  destination: function (req, file, callback) {
    callback(null, path.join(__dirname, "uploads"));
  },
  filename: function (req, file, callback) {
    uidSafe(24).then(function (uid) {
      callback(null, uid + path.extname(file.originalname));
    });
  },
});

const uploader = multer({
  storage: diskStorage,
  limits: {
    fileSize: 2097152,
  },
});

const aws = require("aws-sdk");

// let secrets;
// if (process.env.NODE_ENV == "production") {
//   secrets = process.env; // in prod the secrets are environment variables
// } else {
//   secrets = require("./secrets.json"); // in dev they are in secrets.json which is listed in .gitignore
// }

const s3 = new aws.S3({
  accessKeyId: process.env.AWS_KEY,
  secretAccessKey: process.env.AWS_SECRET,
});

app.use(express.static(path.join(__dirname, "public")));
app.use(express.json());

app.get("/cities", (req, res) => {
  res.json([]);
});

app.post("/images", uploader.single("file"), (req, res) => {
  console.log(req.file);

  const { filename, mimetype, size, path } = req.file;

  const promise = s3
    .putObject({
      Bucket: "spicedling",
      ACL: "public-read",
      Key: filename,
      Body: fs.createReadStream(path),
      ContentType: mimetype,
      ContentLength: size,
    })
    .promise();

  promise
    .then(() => {
      console.log("success");
      // it worked!!!
      res.json({});
    })
    .catch((err) => {
      // uh oh
      console.log(err);
    });
});

app.get("*", (req, res) => {
  res.sendFile(path.join(__dirname, "index.html"));
});

app.listen(PORT, () => console.log(`I'm listening on port ${PORT}`));
```

```js
import * as Vue from "./vue.js";

Vue.createApp({
  methods: {
    emphasize(e) {
      e.target.style.textDecoration = "underline";
      this.count++;
    },
    deemphasize(e) {
      e.target.style.textDecoration = "";
    },
    uploadImage() {
      const file = document.querySelector("input[type=file]").files[0];
      const formData = new FormData();

      formData.append("file", file);

      fetch("/images", {
        method: "POST",
        body: formData,
      });
    },
  },
  data() {
    return {
      headline: "My Image Board",
      name: "Sven",
      count: 0,
      state: "loading",
      headlineCssClass: "head_line",
      card: {
        url: "https://picsum.photos/200/300",
      },
      cities: [],
    };
  },
  mounted() {
    this.state = "mounted";

    fetch("/cities")
      .then((res) => res.json())
      .then((cities) => {
        this.cities = cities;
      });
  },
}).mount("#main");
```